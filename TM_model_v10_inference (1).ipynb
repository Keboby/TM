{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TM_model_v10_inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39M9KYzRUXXF"
      },
      "source": [
        "### Data and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y04QI5_ISORp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814fa028-714d-405d-8f1c-e42a587d408f"
      },
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "!pip install mido\n",
        "import mido\n",
        "from random import randint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mido\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▍                         | 10 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51 kB 3.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: mido\n",
            "Successfully installed mido-1.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MdP2EYzUNvX",
        "outputId": "f3a1db71-f7d5-41e9-d5f3-18e9a60f1f65"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oafR4wnUPca"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR2cc4QrVE7x"
      },
      "source": [
        "> ## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGSRCJ6W1Joc"
      },
      "source": [
        "# custom layers for subclassed model\n",
        "from keras import layers\n",
        "class EncoderBlock(keras.layers.Layer):\n",
        "    def __init__(self,units=200,name='encblock',**kwargs):\n",
        "        super().__init__()\n",
        "        self.conv1 = layers.Conv1D(filters=32,kernel_size=4,strides=4)\n",
        "        self.conv2 = layers.Conv1D(filters=64,kernel_size=4,strides=2)\n",
        "        self.blstm = layers.Bidirectional(layers.LSTM(units))\n",
        "    def call(self,inputs):\n",
        "        inputs=self.conv1(inputs)\n",
        "        inputs=self.conv2(inputs)\n",
        "        #n_steps = tf.shape(inputs)[1]\n",
        "        hidden_state = self.blstm(inputs)\n",
        "        return hidden_state\n",
        "        #for i in range(n_steps): #backward pass\n",
        "            #hidden_b,stateb = self.lstm_cell(inputs[n_steps-i-1,:],states=stateb) \n",
        "        #return tf.concat([hidden_f,hidden_b],axis=0)\n",
        "\n",
        "class Sampling(keras.layers.Layer):\n",
        "    def call(self,inputs):\n",
        "        z_mean,z_log_var=inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = keras.backend.random_normal(shape=(batch,dim))\n",
        "        return z_mean + tf.exp(0.5*z_log_var) * epsilon\n",
        "\n",
        "class VIB_Block(keras.layers.Layer):\n",
        "    def __init__(self,units2=500,latent_units=256,name='vib_block'):\n",
        "        super().__init__()\n",
        "        self.layer2=layers.Dense(units2)\n",
        "        self.z_mean=layers.Dense(latent_units)\n",
        "        self.z_log_var=layers.Dense(latent_units)\n",
        "    def call(self,inputs):\n",
        "        inputs=self.layer2(inputs)\n",
        "        z_mean = self.z_mean(inputs)\n",
        "        z_log_var = self.z_log_var(inputs)\n",
        "        z = Sampling()([z_mean,z_log_var])\n",
        "        return z\n",
        "\n",
        "\n",
        "class ConductorRNN(keras.layers.Layer):\n",
        "    def __init__(self,units=256,name='conductorRNN',**kwargs):\n",
        "        super(ConductorRNN,self).__init__(name=name,**kwargs)\n",
        "        self.lstm_cell = layers.LSTMCell(units)\n",
        "    def call(self,x,num_splits):\n",
        "        predictions=[]\n",
        "        state=self.lstm_cell.get_initial_state(x)\n",
        "        for i in range(num_splits):\n",
        "            x,state = self.lstm_cell(x,states=state)\n",
        "            predictions.append(x)\n",
        "        return predictions\n",
        "        \n",
        "class InferenceDecoderLSTM(keras.layers.Layer):\n",
        "    def __init__(self,units=256,name='inference_lstm',steps=32,**kwargs):\n",
        "        super().__init__()\n",
        "        self.lstm_cell1 = layers.LSTMCell(units)\n",
        "        self.lstm_cell2 = layers.LSTMCell(units)\n",
        "        self.dense1 = layers.Dense(9,activation='sigmoid',name='notes')\n",
        "        self.dense2 = layers.Dense(9,activation='sigmoid',name='vel')\n",
        "        self.dense3 = layers.Dense(9,activation='tanh',name='time')\n",
        "    def call(self,c,initial_state,steps):\n",
        "        predictions=[]\n",
        "        state1=initial_state\n",
        "        state2=self.lstm_cell2.get_initial_state(c)\n",
        "        x=tf.zeros([c.shape[0],27]) # batch,27\n",
        "        for i in range(steps):\n",
        "            x,state1 = self.lstm_cell1(tf.concat([x,c],axis=1),states=state1) # (batch, 27+256) \n",
        "            x,state2 = self.lstm_cell2(x,states=state2)\n",
        "            notes=self.dense1(x)\n",
        "            vel=self.dense2(x)\n",
        "            time=self.dense3(x)\n",
        "            x=tf.concat([notes,vel,time],axis=1)\n",
        "            predictions.append(x)\n",
        "        return tf.stack(predictions,axis=1)\n",
        "\n",
        "class State_Embedder(keras.layers.Layer):\n",
        "    def __init__(self,units=256,name='state_Embedder',**kwargs):\n",
        "        super().__init__()\n",
        "        self.dense=layers.Dense(units*2,activation='tanh')\n",
        "    def call(self,c):\n",
        "        c=self.dense(c)\n",
        "        return tf.split(c,2,axis=1)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QXg2imJVHW6"
      },
      "source": [
        "class InferenceModel(keras.Model):\n",
        "    def __init__(self,units_list,name='my_model',**kwargs):\n",
        "        super(InferenceModel,self).__init__(name=name,**kwargs)\n",
        "        units_enc,units2,latent_units,units_dec = units_list\n",
        "        self.encblock1 = EncoderBlock(units_enc)\n",
        "        self.encblock2 = EncoderBlock(units_enc)\n",
        "        self.encblock3 = EncoderBlock(units_enc)\n",
        "        self.vibblock = VIB_Block(units2=units2,latent_units=latent_units)\n",
        "        self.conductor = ConductorRNN(latent_units)\n",
        "        self.embedder = State_Embedder(units_dec)\n",
        "        self.dec = InferenceDecoderLSTM(units=units_dec)\n",
        "    def call(self,inputs,steps=32):\n",
        "        #inputs\n",
        "        X1,X2,X3 = inputs\n",
        "        n_steps = X1.shape[1]\n",
        "        #encoder\n",
        "        x1 = self.encblock1(X1)\n",
        "        x2 = self.encblock2(X2)\n",
        "        x3 = self.encblock3(X3)\n",
        "        z = self.vibblock(tf.concat([x1,x2,x3],axis=1))\n",
        "        #decoder\n",
        "        n_splits = math.ceil(n_steps/steps)\n",
        "        remainder_steps = n_steps%steps\n",
        "        c_embeddings = self.conductor(z,n_splits)\n",
        "        dec_outputs = [] \n",
        "        for i,c in enumerate(c_embeddings):\n",
        "            if i == n_splits-1 and remainder_steps>0: #last split and some steps left\n",
        "                steps=remainder_steps\n",
        "            subseq_output=self.dec(c=c,initial_state=self.embedder(c),steps=steps)\n",
        "            dec_outputs.append(subseq_output)\n",
        "        model_outputs=tf.concat(dec_outputs,axis=1) # (batch,n_steps,27)\n",
        "        return model_outputs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s9WFn6vMDPt",
        "outputId": "b051bc4b-178b-4145-8729-df31062489f2"
      },
      "source": [
        "units_enc,units2,latent_units,units_dec = 200,500,256,256 \n",
        "model = InferenceModel(\n",
        "    units_list=[units_enc,units2,latent_units,units_dec],\n",
        "    name='Inference Model'\n",
        ")\n",
        "model.build([(1,128,128),(1,128,128),(1,128,128)])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Inference Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_block (EncoderBlock) multiple                  448672    \n",
            "_________________________________________________________________\n",
            "encoder_block_1 (EncoderBloc multiple                  448672    \n",
            "_________________________________________________________________\n",
            "encoder_block_2 (EncoderBloc multiple                  448672    \n",
            "_________________________________________________________________\n",
            "vib__block (VIB_Block)       multiple                  857012    \n",
            "_________________________________________________________________\n",
            "conductorRNN (ConductorRNN)  multiple                  525312    \n",
            "_________________________________________________________________\n",
            "state__embedder (State_Embed multiple                  131584    \n",
            "_________________________________________________________________\n",
            "inference_decoder_lstm (Infe multiple                  1085211   \n",
            "=================================================================\n",
            "Total params: 3,945,135\n",
            "Trainable params: 3,945,135\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmkuGUW3kIUn"
      },
      "source": [
        "> ## loading weights to the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhi6BxXcu9Tx"
      },
      "source": [
        "\"\"\"#code used to create the list manually\n",
        "for layer in model.layers:\n",
        "    print(layer.name)\n",
        "    print('\\t', [w.shape for w in layer.get_weights()])\n",
        "\"\"\"\n",
        "manual_keys =[\n",
        "    ['0/kernel','0/bias','3/kernel','3/bias',\n",
        "    '6/forward_layer/cell/kernel','6/forward_layer/cell/recurrent_kernel','6/forward_layer/cell/bias',\n",
        "    '6/backward_layer/cell/kernel','6/backward_layer/cell/recurrent_kernel','6/backward_layer/cell/bias',\n",
        "    ],\n",
        "    ['1/kernel','1/bias','4/kernel','4/bias',\n",
        "    '7/forward_layer/cell/kernel','7/forward_layer/cell/recurrent_kernel','7/forward_layer/cell/bias',\n",
        "    '7/backward_layer/cell/kernel','7/backward_layer/cell/recurrent_kernel','7/backward_layer/cell/bias',\n",
        "    ],\n",
        "    ['2/kernel','2/bias','5/kernel','5/bias',\n",
        "    '8/forward_layer/cell/kernel','8/forward_layer/cell/recurrent_kernel','8/forward_layer/cell/bias',\n",
        "    '8/backward_layer/cell/kernel','8/backward_layer/cell/recurrent_kernel','8/backward_layer/cell/bias',\n",
        "    ],\n",
        "    ['9/kernel','9/bias','10/kernel','10/bias','11/kernel','11/bias'],\n",
        "    ['12/lstm_cell/kernel','12/lstm_cell/recurrent_kernel','12/lstm_cell/bias'],\n",
        "    ['13/dense/kernel','13/dense/bias'],\n",
        "    ['14/cell/kernel','14/cell/recurrent_kernel','14/cell/bias',\n",
        "     '15/cell/kernel','15/cell/recurrent_kernel','15/cell/bias',\n",
        "     '16/layer/kernel','16/layer/bias','17/layer/kernel','17/layer/bias','18/layer/kernel','18/layer/bias'\n",
        "    ]]\n",
        "for i,keylist in enumerate(manual_keys):\n",
        "    for j,key in enumerate(keylist):\n",
        "        manual_keys[i][j]= 'layer_with_weights-'+key+'/.ATTRIBUTES/VARIABLE_VALUE'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vMwy_f5PEGI"
      },
      "source": [
        "filepath='/content/drive/MyDrive/TM-backup/checkpoints_v8/tm-model-v8'\n",
        "reader = tf.train.load_checkpoint(filepath)\n",
        "shape_from_key = reader.get_variable_to_shape_map()\n",
        "useful_keys=[]\n",
        "for key in sorted(shape_from_key.keys()):\n",
        "    if key[len(key)-28] == 's' or key[len(key)-28]=='l': # eliminates unnecessary keys (the ones used in the optimizer, etc.) \n",
        "            useful_keys.append(key)\n",
        "for i,layer in enumerate(model.layers):\n",
        "    layer.set_weights([reader.get_tensor(key) for key in manual_keys[i]])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF8bb9HUmcFA"
      },
      "source": [
        "## Variable-sized inputs (inference test on real music)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq0uvHYagBm3"
      },
      "source": [
        "def array_on_track(track,ticks):\n",
        "    first_array = np.zeros(shape=(len(track),3))\n",
        "    time = 0 #ticks\n",
        "    for i,msg in enumerate(track):\n",
        "        time+=msg.time\n",
        "        if msg.type=='control_change' or msg.type=='program_change' or msg.type=='note_off':\n",
        "            continue\n",
        "        elif not msg.is_meta: # we only want note_on messages\n",
        "            first_array[i,0]=1\n",
        "            first_array[i,1]=msg.bytes()[1] #note_value 0..127\n",
        "            first_array[i,2]=round(time*4/ticks) #quantized time in ticks\n",
        "    # we have now an event-based list of notes\n",
        "    # let's transform it into a time series with note value on the second dimension\n",
        "    \n",
        "    second_array = np.zeros(shape=(round(time*4/ticks),128))\n",
        "    for note in first_array:\n",
        "        if note[0]==1:\n",
        "            second_array[int(note[2]),int(note[1])]=1\n",
        "    # in doing so, we skipped the data regarding velocity and note_off events\n",
        "    # but, as this is just the input for the model and won't be used to create midifiles,\n",
        "    # we can allow ourselves to simplify the data \n",
        "    return second_array"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvqaC1e_k9Xe"
      },
      "source": [
        "def drum_array_on_track(track,ticks):\n",
        "    first_array = np.zeros(shape=(len(track),5))\n",
        "    time = 0 #ticks\n",
        "    \n",
        "    #converting standard drum notation to indexes 0-8\n",
        "    gm_to_ix ={\n",
        "        35:0,36:0,\n",
        "        37:1,38:1,39:1,40:1,\n",
        "        42:2,44:2,\n",
        "        46:3,\n",
        "        41:4,43:4,\n",
        "        45:5,47:5,\n",
        "        48:6,50:6,\n",
        "        51:7,53:7,59:7,\n",
        "        49:8,52:8,55:8,57:8\n",
        "    }\n",
        "    #kick,snare,HHc,HHo,tom3,tom2,tom1,ride,crash\n",
        "    #0   ,1    ,2  ,3  ,4   ,5   ,6   ,7   ,8\n",
        "    \n",
        "    for i,msg in enumerate(track):\n",
        "        time+=msg.time\n",
        "        if msg.type=='control_change' or msg.type=='program_change' or msg.type=='note_off':\n",
        "            continue\n",
        "        elif not msg.is_meta:\n",
        "            if msg.bytes()[1] in gm_to_ix.keys(): # to prevent key errors\n",
        "                first_array[i,0]=1 #note or no note \n",
        "                first_array[i,1]=gm_to_ix[msg.bytes()[1]] #note_value 0-8\n",
        "                first_array[i,2]=msg.bytes()[2]/127 #velocity : float 0..1\n",
        "                first_array[i,3]=round(time*4/ticks) #quantized time in ticks\n",
        "                first_array[i,4]=(time*4/ticks)-round(time*4/ticks) #offset in ticks\n",
        "    #####\n",
        "    #let's create the time series array:\n",
        "    second_array=np.zeros((round(time*4/ticks),27))\n",
        "    \n",
        "    for note in first_array:\n",
        "        if note[0]==1:\n",
        "            second_array[int(note[3]),int(note[1])]=1 # note\n",
        "            second_array[int(note[3]),9+int(note[1])]=note[2] # vel\n",
        "            second_array[int(note[3]),18+int(note[1])]=note[4] # time offset\n",
        "    return second_array "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWIVxkjbfdUv"
      },
      "source": [
        "def create_arrays(filename):\n",
        "    file = mido.MidiFile(filename)\n",
        "\n",
        "    ticks = file.ticks_per_beat\n",
        "    \n",
        "    piano_ix=[]\n",
        "    guitar_ix=[]\n",
        "    bass_ix=[]\n",
        "    #i_drums=-1\n",
        "    piano_range = range(0,8)\n",
        "    guitar_range = range(24,32)\n",
        "    bass_range = range(32,40)\n",
        "    \n",
        "    ##### filtering tracks:\n",
        "    for i,track in enumerate(file.tracks):\n",
        "        for msg in track[0:20]:\n",
        "            if msg.is_meta == False:\n",
        "                if msg.type=='program_change':\n",
        "                    #if msg.dict()['channel'] ==9:\n",
        "                    #    i_drums=i\n",
        "                    if msg.dict()['program'] in piano_range:\n",
        "                        piano_ix.append(i)\n",
        "                    elif msg.dict()['program'] in guitar_range:\n",
        "                        guitar_ix.append(i)\n",
        "                    elif msg.dict()['program'] in bass_range:\n",
        "                        bass_ix.append(i)\n",
        "    #####\n",
        "    created=False\n",
        "    #drum_array1 = drum_array_on_track(file.tracks[i_drums],ticks)\n",
        "    #max_length = drum_array1.shape[0]\n",
        "    max_length=None\n",
        "    combinations = []\n",
        "    for i_piano in piano_ix:\n",
        "        for i_guitar in guitar_ix:\n",
        "            for i_bass in bass_ix:\n",
        "                #this loops over all possibilities for these instruments \n",
        "                piano_array1 = array_on_track(file.tracks[i_piano],ticks)\n",
        "                guitar_array1 = array_on_track(file.tracks[i_guitar],ticks)\n",
        "                bass_array1 = array_on_track(file.tracks[i_bass],ticks)\n",
        "\n",
        "                max_length = bass_array1.shape[0] if max_length is None else max_length\n",
        "                \n",
        "                piano_final=piano_array1[:max_length,:].copy().reshape(1,max_length,128)\n",
        "                guitar_final=guitar_array1[:max_length,:].copy().reshape(1,max_length,128)\n",
        "                bass_final=bass_array1[:max_length,:].copy().reshape(1,max_length,128)\n",
        "                combinations.append([piano_final,guitar_final,bass_final])\n",
        "    return combinations #,drum_array1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMM7anKwrH4z"
      },
      "source": [
        "def sample(notes,temp):\n",
        "    length=notes.shape[len(notes.shape)-2]\n",
        "    notes=notes.numpy().reshape((length,9))\n",
        "    for timestep in range(length):\n",
        "        for i,note in enumerate(notes[timestep]):\n",
        "            if note>temp:\n",
        "                notes[timestep,i]=1\n",
        "            else:\n",
        "                notes[timestep,i]=0\n",
        "    return notes"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNKYDzxk5voa"
      },
      "source": [
        "def array_to_midi(array,filename,remove_real_drums=False):\n",
        "    \"\"\" \"array\" is of shape (length,27) with ones and zeros at first, then float predictions.\n",
        "        \"filename\" is the file name of the original midi song (without drums preferably)\n",
        "    \"\"\"\n",
        "\n",
        "    file=mido.MidiFile(filename)\n",
        "    upscale_factor = file.ticks_per_beat/4 \n",
        "    \n",
        "    if remove_real_drums:\n",
        "        percussions=[]\n",
        "        for i,track in enumerate(file.tracks):\n",
        "            for msg in track[0:20]:\n",
        "                if msg.is_meta == False:\n",
        "                    if msg.type=='program_change':\n",
        "                        if msg.dict()['channel'] ==9:\n",
        "                            percussions.append(track)\n",
        "        for track in percussions:\n",
        "            file.tracks.remove(track)\n",
        "    \n",
        "    track=mido.MidiTrack()\n",
        "    file.tracks.append(track)\n",
        "    track2=mido.MidiTrack()\n",
        "    file.tracks.append(track2)\n",
        "    track_quantized=mido.MidiTrack()\n",
        "    file.tracks.append(track_quantized)\n",
        "    track_quantized2=mido.MidiTrack()\n",
        "    file.tracks.append(track_quantized2)\n",
        "    \n",
        "    #---\n",
        "    canonical_list=[36,38,42,43,46,47,49,50,51]\n",
        "    ix_to_canonical={i:val for i,val in enumerate(canonical_list)}\n",
        "    msgs=[]\n",
        "\n",
        "    for timestep in range(array.shape[0]):\n",
        "        for i,note in enumerate(array[timestep,:9]):\n",
        "            if note==1:\n",
        "                if timestep!=0:\n",
        "                    msgs.append([\n",
        "                                ix_to_canonical[i],\n",
        "                                round(array[timestep,9+i]*127),\n",
        "                                round((timestep+array[timestep,18+i])*upscale_factor)\n",
        "                                ])\n",
        "                else:\n",
        "                    msgs.append([\n",
        "                                ix_to_canonical[i],\n",
        "                                round(array[timestep,9+i]*127),\n",
        "                                round(timestep*upscale_factor) # to prevent a negative time for the first message\n",
        "                                ])\n",
        "    for msg in msgs: # after some tests i realized that the drums volume was too low \n",
        "        new_vel = int(msg[1]*1.8) if msg[0]!=38 else int(msg[1]*2.5)\n",
        "        msg[1]= new_vel if new_vel<=127 else 127\n",
        "\n",
        "    #---\n",
        "    # transforming from absolute time in ticks to delta time in ticks\n",
        "    d=0\n",
        "    for msg in msgs:\n",
        "        d,msg[2]=msg[2],msg[2]-d  #python is beautiful \n",
        "        # d is absolute time of previous message,\n",
        "        # msg[2] (=the msg's absolute time) now becomes the difference between the absolute times of itself and the previous msg\n",
        "    #----\n",
        "    # adding note off msgs to other track (track2) to later merge both\n",
        "    delta=1*upscale_factor\n",
        "\n",
        "    for i,msg in enumerate(msgs):\n",
        "        track.append(mido.Message('note_on',channel=9,note=msg[0],velocity=int(msg[1]),time=int(msg[2])))\n",
        "        track_quantized.append(mido.Message('note_on',channel=9,note=msg[0],velocity=90,time=int(upscale_factor*round(msg[2]/upscale_factor))))\n",
        "        if i==0:\n",
        "            track2.append(mido.Message('note_off',channel=9,note=msg[0],velocity=int(msg[1]),time=int(msg[2]+delta)))\n",
        "            track_quantized2.append(mido.Message('note_off',channel=9,note=msg[0],velocity=90,time=int(upscale_factor*round(msg[2]/upscale_factor)+delta)))\n",
        "        else:\n",
        "            track2.append(mido.Message('note_off',channel=9,note=msg[0],velocity=int(msg[1]),time=int(msg[2])))\n",
        "            track_quantized2.append(mido.Message('note_off',channel=9,note=msg[0],velocity=90,time=int(upscale_factor*round(msg[2]/upscale_factor))))\n",
        "    new_track=mido.merge_tracks([track,track2])\n",
        "    new_track.name='generated_drums'\n",
        "\n",
        "    new_track_quantized=mido.merge_tracks([track_quantized,track_quantized2])\n",
        "    new_track_quantized.name='quantized_drums'\n",
        "\n",
        "    file.tracks.append(new_track)\n",
        "    file.tracks.remove(track)\n",
        "    file.tracks.remove(track2)\n",
        "    file.tracks.append(new_track_quantized)\n",
        "    file.tracks.remove(track_quantized)\n",
        "    file.tracks.remove(track_quantized2)\n",
        "    return file"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j82uNTaq91mF"
      },
      "source": [
        "def evaluate_rythms(rythms):\n",
        "    \"\"\" Construisons une fonction pour choisir le meilleur rythme de batterie parmi tous ceux générés.\n",
        "        J'ai 2 approches en tête: la première est de modéliser et d'entraîner un petit modèle \"discriminant\",\n",
        "        potentiellement similaire à la deuxième partie d'un GAN;\n",
        "        la deuxième – plus simple – serait de créer une fonction discriminante à la main,\n",
        "        en évaluant par exemple la distance moyenne des rythmes générés à un \"rythme type\" arbitraire, judicieusement choisi. \n",
        "        (Ainsi on peut pénaliser les rythmes à la fois trop simples ou trop complexes)\n",
        "        NB: l'input \"rythms\" est une liste de la forme [notes générées, prédictions , température].\n",
        "    \"\"\"\n",
        "    #Ci-dessous se trouve un rythme (sous forme de matrice) assez basique, mais suffisant pour faire office d'exemple et classer les rythmes générés.\n",
        "    baseline_rythm = np.array( \n",
        "        [[1,0,1,0,0,0,0,0,1],[0,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0],\n",
        "        [0,1,1,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0],\n",
        "        [1,0,1,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0],[1,0,1,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0],\n",
        "        [0,1,1,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0],[0,0,1,1,0,0,0,0,0],[0,0,0,0,0,0,0,0,0]])\n",
        "    discriminating_fx = keras.metrics.Accuracy()\n",
        "    metrics=[]\n",
        "    length=rythms[0][0].shape[0]\n",
        "    labels= np.tile(baseline_rythm, [math.ceil(length/baseline_rythm.shape[0]),1])[:length,:]\n",
        "    for r in rythms:\n",
        "        metrics.append(discriminating_fx(labels,r[0]))\n",
        "    return rythms[metrics.index(max(metrics))]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA-B71zmmINt"
      },
      "source": [
        "def real_inference(file,model,temp=None,dec_steps=32):\n",
        "    n= input('test number? (for filename) : ')\n",
        "    if temp is None:\n",
        "        temp_range=[0.6,0.62,0.64]\n",
        "    elif type(temp) is float:\n",
        "        temp_range=[temp]\n",
        "\n",
        "    combinations = create_arrays(file) \n",
        "    rythms = []\n",
        "    for i,combination in enumerate(combinations):\n",
        "        predictions = model(inputs=combination,steps=dec_steps)\n",
        "        for temp in temp_range:\n",
        "            predictions_ones = sample(predictions[:,:,:9],temp)\n",
        "            rythms.append([predictions_ones,predictions,temp])\n",
        "\n",
        "    predictions_ones,chosen_predictions,final_temp = evaluate_rythms(rythms)\n",
        "    chosen_predictions= chosen_predictions[:,:,9:].numpy().reshape((predictions_ones.shape[0],18))\n",
        "    final_predictions = np.concatenate([predictions_ones,chosen_predictions],axis=1)\n",
        "\n",
        "    midifile = array_to_midi(final_predictions,file)\n",
        "    midifile.save(f'inference-test-v8-file-{n}.mid')\n",
        "    print('temp :',final_temp)\n",
        "    print('decoder steps :',dec_steps)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84HXAUUJ5dUm",
        "outputId": "6c7ffd6b-3327-41ad-d518-a139ddfa7a7f"
      },
      "source": [
        "real_inference('/content/drive/MyDrive/TM-backup/Sofarawayfromme.mid',model,temp=0.62,dec_steps=16)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test number? (for filename) : 11\n",
            "temp : 0.62\n",
            "decoder steps : 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIntAb3Z-tYY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
