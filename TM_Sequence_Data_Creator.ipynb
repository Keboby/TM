{
 "cells": [  
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [f'datasets/TM_dataset_enc9_part{i}.npz' for i in range(1,6)] \n",
    "batch_size=64\n",
    "counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for k,dataset_path in enumerate(dataset_paths):\n",
    "    print(f'dataset part {k} :')\n",
    "    try :\n",
    "        print('loading...')\n",
    "        loaded = np.load(dataset_path) \n",
    "        array_drum = loaded['array1_drm']\n",
    "        array_piano = loaded['array2_pia']\n",
    "        array_gtr = loaded['array3_gtr']\n",
    "        array_bass = loaded['array4_bss']\n",
    "\n",
    "        num_samples = array_drum.shape[0]\n",
    "        num_batches = int(num_samples/batch_size)\n",
    "        print(f'\\tnum samples: {num_samples}')\n",
    "        print(f'\\tnum batches: {num_batches}')\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            counter+=1\n",
    "            if counter%100==0:\n",
    "                print(f'\\t{counter} batches done')\n",
    "            path=f'datasets/data_for_sequence/batch_{counter}'\n",
    "\n",
    "            np.savez_compressed(\n",
    "                path,\n",
    "                array1_drm=array_drum[i*batch_size:(i+1)*batch_size],\n",
    "                array2_pia=array_piano[i*batch_size:(i+1)*batch_size],\n",
    "                array3_gtr=array_gtr[i*batch_size:(i+1)*batch_size],\n",
    "                array4_bss=array_bass[i*batch_size:(i+1)*batch_size],\n",
    "            )\n",
    "    except:\n",
    "        print(f'Error! {sys.exc_info()[0]} occurred')\n",
    "        break\n",
    "            \n",
    "print()\n",
    "print(f'{counter} batches created from {counter*batch_size} files')\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of files per subdataset:\n",
    "    #part1: 122538 files, 1914 batches\n",
    "    #part2: 116751 files, 1814 batches\n",
    "    #part3: 101364 files, 1583 batches\n",
    "    #part4: ca 109651 files, 1725 batches\n",
    "    #part5: 106954 files, 1671 batches\n",
    "# total batches 8707\n",
    "# total files read 557248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset part 5 :\n",
      "loading...\n",
      "\tnum samples: 106954\n",
      "\tnum batches: 1671\n",
      "\t7100 batches done\n",
      "\t7200 batches done\n",
      "\t7300 batches done\n",
      "\t7400 batches done\n",
      "\t7500 batches done\n",
      "\t7600 batches done\n",
      "\t7700 batches done\n",
      "\t7800 batches done\n",
      "\t7900 batches done\n",
      "\t8000 batches done\n",
      "\t8100 batches done\n",
      "\t8200 batches done\n",
      "\t8300 batches done\n",
      "\t8400 batches done\n",
      "\t8500 batches done\n",
      "\t8600 batches done\n",
      "\t8700 batches done\n",
      "8707 batches created from 557248 files as of now\n"
     ]
    }
   ],
   "source": [
    "counter=7036\n",
    "n=5\n",
    "print(f'dataset part {n} :')\n",
    "print('loading...')\n",
    "dataset_path=f'datasets/TM_dataset_enc9_part{n}.npz'\n",
    "\n",
    "loaded = np.load(dataset_path) \n",
    "array_drum = loaded['array1_drm']\n",
    "array_piano = loaded['array2_pia']\n",
    "array_gtr = loaded['array3_gtr']\n",
    "array_bass = loaded['array4_bss']\n",
    "\n",
    "num_samples = array_drum.shape[0]\n",
    "num_batches = int(num_samples/batch_size)\n",
    "print(f'\\tnum samples: {num_samples}')\n",
    "print(f'\\tnum batches: {num_batches}')\n",
    "\n",
    "for i in range(num_batches):\n",
    "    counter+=1\n",
    "    if counter%100==0:\n",
    "        print(f'\\t{counter} batches done')\n",
    "    path=f'datasets/data_for_sequence/batch_{counter}'\n",
    "\n",
    "    np.savez_compressed(\n",
    "        path,\n",
    "        array1_drm=array_drum[i*batch_size:(i+1)*batch_size],\n",
    "        array2_pia=array_piano[i*batch_size:(i+1)*batch_size],\n",
    "        array3_gtr=array_gtr[i*batch_size:(i+1)*batch_size],\n",
    "        array4_bss=array_bass[i*batch_size:(i+1)*batch_size],\n",
    "    )\n",
    "print(f'{counter} batches created from {counter*batch_size} files as of now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,dataset_path,length,batch_size,pad=1):\n",
    "        self.dataset_path=dataset_path\n",
    "        self.length=length\n",
    "        self.batch_size=batch_size\n",
    "        self.paddings=tf.constant([[0,0], [pad,0], [0,0]])\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self,idx):\n",
    "        loaded = np.load(str(self.dataset_path+'/batch_'+str(int(idx+1))))\n",
    "        array1 = loaded['array1_drm']\n",
    "        array2 = loaded['array2_pia']\n",
    "        array3 = loaded['array3_gtr']\n",
    "        array4 = loaded['array4_bss']\n",
    "        dec_input = tf.slice(tf.pad(array1,paddings=self.paddings),[0,0,0],array1.shape)\n",
    "        inputs = [\n",
    "            array2,array3,array4,\n",
    "            dec_input[:,:,:9],\n",
    "            dec_input[:,:,9:18],\n",
    "            dec_input[:,:,18:27]\n",
    "        ]\n",
    "        return inputs,array1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
